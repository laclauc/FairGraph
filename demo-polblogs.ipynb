{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d044559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from src.main import *\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib.lines import Line2D\n",
    "from src.generate_graph import *\n",
    "from src.link_prediction import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651df012",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 21\n",
    "stellargraph.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Polblogs\n",
    "path_data = \"data/\"\n",
    "g, labArray = loadPolblog(path_data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524196fa",
   "metadata": {},
   "source": [
    "## Repairing with OT (EMD version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repair the graph\n",
    "emd_x_l, s, gamma, M = total_repair_emd(g)\n",
    "emd_g = nx.from_numpy_matrix(emd_x_l)\n",
    "\n",
    "# Remove edges with small weights to have similar density with original graph\n",
    "list_edge = [(u, v) for (u, v, d) in emd_g.edges(data=True) if d['weight'] < 0.5]\n",
    "emd_g.remove_edges_from(list_edge)\n",
    "lab = {k: j for k, j in zip(emd_g.nodes, labArray[:, 1])}\n",
    "g_emd = nx.relabel_nodes(emd_g, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f868a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.density(g))\n",
    "print(nx.density(g_emd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa539e",
   "metadata": {},
   "source": [
    "## Link prediction\n",
    "\n",
    "We are now ready to illustrate the impact of the repairing on the node embeddings and the link prediction task. \n",
    "To proceed, we use the Stellar library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809c3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcd7c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two graphs with stellar format (original and repaired one)\n",
    "stellar_polblogs_emd = StellarGraph.from_networkx(g_emd)\n",
    "stellar_polblogs_lap = StellarGraph.from_networkx(g_lap)\n",
    "stellar_polblogs = StellarGraph.from_networkx(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5337e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(g.nodes(data='value'))\n",
    "lab_node_list = [(node_list.index(i), i[0]) for i in node_list]\n",
    "lab_node_array = np.array(lab_node_list)\n",
    "\n",
    "def Convert(tup):\n",
    "    dic = dict(tup)\n",
    "    return dic\n",
    "\n",
    "tups = node_list\n",
    "dictionary = {}\n",
    "protS = Convert(tups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc4398",
   "metadata": {},
   "source": [
    "### Link prediction with OT-emd repaired graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1402bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 3470 positive and 3470 negative edges. **\n",
      "** Sampled 2429 positive and 2429 negative edges. **\n",
      "Number of random walks for 'Train Graph': 12240\n",
      "ROC AUC score on test set using 'operator_hadamard': 0.6710029556396165\n",
      "DI score on test set using 'operator_hadamard': 0.45708446866485014\n",
      "Consistency score on test set using 'operator_hadamard': 0.9024888656012575\n",
      "** Sampled 3470 positive and 3470 negative edges. **\n",
      "** Sampled 2429 positive and 2429 negative edges. **\n",
      "Number of random walks for 'Train Graph': 12240\n",
      "ROC AUC score on test set using 'operator_hadamard': 0.6531271399825775\n",
      "DI score on test set using 'operator_hadamard': 0.5647249190938511\n",
      "Consistency score on test set using 'operator_hadamard': 0.9185747969609641\n",
      "** Sampled 3470 positive and 3470 negative edges. **\n",
      "** Sampled 2429 positive and 2429 negative edges. **\n",
      "Number of random walks for 'Train Graph': 12240\n",
      "ROC AUC score on test set using 'operator_hadamard': 0.6620515765602953\n",
      "DI score on test set using 'operator_hadamard': 0.4727272727272727\n",
      "Consistency score on test set using 'operator_hadamard': 0.9957034320146712\n",
      "** Sampled 3470 positive and 3470 negative edges. **\n",
      "** Sampled 2429 positive and 2429 negative edges. **\n",
      "Number of random walks for 'Train Graph': 12240\n",
      "ROC AUC score on test set using 'operator_hadamard': 0.6769217916506801\n",
      "DI score on test set using 'operator_hadamard': 0.4369063772048847\n",
      "Consistency score on test set using 'operator_hadamard': 0.9073225045847524\n",
      "** Sampled 3470 positive and 3470 negative edges. **\n",
      "** Sampled 2429 positive and 2429 negative edges. **\n",
      "Number of random walks for 'Train Graph': 12240\n",
      "ROC AUC score on test set using 'operator_hadamard': 0.6646981994706171\n",
      "DI score on test set using 'operator_hadamard': 1.25\n",
      "Consistency score on test set using 'operator_hadamard': 0.9996201205134922\n",
      "Done !\n",
      "Average AUC over 10 trials:     0.67 (    0.01) \n",
      "Average DI over 10 trials:     0.64 (    0.31) \n",
      "Average Consistency over 10 trials:     0.94 (    0.04) \n",
      "Average Representation Bias over 10 trials:     0.79 (    0.01) \n"
     ]
    }
   ],
   "source": [
    "auc, di, cons, rep_bias = [], [], [], []\n",
    "# Note that we use 10 trials for the paper\n",
    "trials = 5\n",
    "\n",
    "for i in range(trials):\n",
    "\n",
    "    # Define an edge splitter on the corrected graph:\n",
    "    edge_splitter_test = EdgeSplitter(stellar_polblogs_emd)\n",
    "    graph_test, examples_test, labels_test = edge_splitter_test.train_test_split(p=0.3, method=\"global\",\n",
    "                                                                                  keep_connected=True)\n",
    "    # Do the same process to compute a training subset from within the test graph\n",
    "    edge_splitter_train = EdgeSplitter(graph_test, stellar_polblogs_emd)\n",
    "    graph_train, examples, labels = edge_splitter_train.train_test_split(p=0.3, method=\"global\", keep_connected=True)\n",
    "    (\n",
    "        examples_train,\n",
    "        examples_model_selection,\n",
    "        labels_train,\n",
    "        labels_model_selection,\n",
    "    ) = train_test_split(examples, labels, train_size=0.75, test_size=0.25)\n",
    "\n",
    "    # Clear labels by removing edges created by the repairing from the test set\n",
    "    for k, i in enumerate(examples_test):\n",
    "        tup = (i[0], i[1])\n",
    "        labels_test[k] = int(g.has_edge(*tup))\n",
    "\n",
    "    for k, i in enumerate(examples_train):\n",
    "        tup = (i[0], i[1])\n",
    "        labels_train[k] = int(g.has_edge(*tup))\n",
    "\n",
    "    for k, i in enumerate(examples_model_selection):\n",
    "        tup = (i[0], i[1])\n",
    "        labels_model_selection[k] = int(g.has_edge(*tup))\n",
    "\n",
    "    # Compute absolute difference for the protected attribute\n",
    "    abs_diff_train = abs_diff(examples_train, protS)\n",
    "    abs_diff_model_selection = abs_diff(examples_model_selection, protS)\n",
    "    abs_diff_test = abs_diff(examples_test, protS)\n",
    "\n",
    "    # Node2vec on the graph train\n",
    "    embedding_train, vec_train, s_train = node2vec_embedding(graph_train, \"Train Graph\", protS)\n",
    "    \n",
    "    # Choose operator for concatenating the embeddings \n",
    "    binary_operators = [operator_hadamard]\n",
    "    results = [run_link_prediction(op, \n",
    "                                   examples_train, \n",
    "                                   labels_train, \n",
    "                                   embedding_train,\n",
    "                                   examples_model_selection,\n",
    "                                   labels_model_selection, \n",
    "                                   abs_diff_model_selection) for op in binary_operators]\n",
    "    best_result = max(results, key=lambda result: result[\"score\"])\n",
    "\n",
    "    auc_protS = representation_bias(vec_train, s_train)\n",
    "    rep_bias.append(auc_protS)\n",
    "\n",
    "    test_score, test_score_bias, test_score_consistency = evaluate_link_prediction_model(\n",
    "        best_result[\"classifier\"],\n",
    "        examples_test,\n",
    "        labels_test,\n",
    "        embedding_train,\n",
    "        best_result[\"binary_operator\"],\n",
    "        abs_diff_test\n",
    "    )\n",
    "    print(f\"ROC AUC score on test set using '{best_result['binary_operator'].__name__}': {test_score}\")\n",
    "    print(f\"DI score on test set using '{best_result['binary_operator'].__name__}': {test_score_bias}\")\n",
    "    print(f\"Consistency score on test set using '{best_result['binary_operator'].__name__}': {test_score_consistency}\")\n",
    "\n",
    "    auc.append(test_score)\n",
    "    di.append(test_score_bias)\n",
    "    cons.append(test_score_consistency)\n",
    "\n",
    "print(\"Done !\")\n",
    "\n",
    "print(\"Average AUC over 10 trials: %8.2f (%8.2f) \" % (np.asarray(auc).mean(), np.asarray(auc).std()))\n",
    "print(\"Average DI over 10 trials: %8.2f (%8.2f) \" % (np.asarray(di).mean(), np.asarray(di).std()))\n",
    "print(\"Average Consistency over 10 trials: %8.2f (%8.2f) \" % (np.asarray(cons).mean(), np.asarray(cons).std()))\n",
    "print(\"Average Representation Bias over 10 trials: %8.2f (%8.2f) \" % (np.asarray(rep_bias).mean(),\n",
    "                                                                      np.asarray(rep_bias).std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
